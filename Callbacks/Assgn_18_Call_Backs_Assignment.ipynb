{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Assgn -18 - Call_Backs_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQDRNrY2NCXf"
      },
      "source": [
        "<pre>\n",
        "1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>\n",
        "\n",
        "2. Code the model to classify data like below image\n",
        "\n",
        "<img src='https://i.imgur.com/33ptOFy.png'>\n",
        "\n",
        "3. Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.\n",
        "\n",
        "4. Save your model at every epoch if your validation accuracy is improved from previous epoch. \n",
        "\n",
        "5. you have to decay learning based on below conditions \n",
        "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
        "               learning rate by 10%. \n",
        "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
        "        \n",
        "6. If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training. \n",
        "\n",
        "7. You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
        "\n",
        "8. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "9. use cross entropy as loss function\n",
        "\n",
        "10. Try the architecture params as given below. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w41Y3TFENCXk"
      },
      "source": [
        "<pre>\n",
        "<b>Model-1</b>\n",
        "<pre>\n",
        "1. Use tanh as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-2</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-3</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use he_uniform() as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-4</b>\n",
        "<pre>\n",
        "1. Try with any values to get better accuracy/f1 score.  \n",
        "</pre>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQSE5syvSvC-",
        "outputId": "b7034656-0a32-4804-8221-4b9906e36d37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G93h1HIG6Jq4"
      },
      "source": [
        "#Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw_lKKFLS2PW"
      },
      "source": [
        "# tf.enable_eager_execution()\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrhJqQOR-d5n"
      },
      "source": [
        "# !pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stZOKH4X-bzF"
      },
      "source": [
        "# import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRSCeb8uQPEh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense,Input,Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUFijWof6Tcm"
      },
      "source": [
        "#Reading and splitting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYEXlw5MS9qd"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nao4XONxTEoz",
        "outputId": "b8aca218-dafd-4c18-c566-50fdb122a6d1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.450564</td>\n",
              "      <td>1.074305</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.085632</td>\n",
              "      <td>0.967682</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.117326</td>\n",
              "      <td>0.971521</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.982179</td>\n",
              "      <td>-0.380408</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.720352</td>\n",
              "      <td>0.955850</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         f1        f2  label\n",
              "0  0.450564  1.074305    0.0\n",
              "1  0.085632  0.967682    0.0\n",
              "2  0.117326  0.971521    1.0\n",
              "3  0.982179 -0.380408    0.0\n",
              "4 -0.720352  0.955850    0.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsqd2N-UGMjj",
        "outputId": "c23d6ad2-891e-4c00-a542-6df631739730"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    10000\n",
              "0.0    10000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FHO1SgKTKQi"
      },
      "source": [
        "x = df.drop('label',axis=1)\n",
        "y = df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1SScxpoTZ2H",
        "outputId": "74cd8c56-93fe-4646-d188-77f44917a6bd"
      },
      "source": [
        "x.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 2), (20000,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEupkQdbT9wl"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqBratEeUOSA",
        "outputId": "d6b5b348-125b-4aa3-fcfd-cc51d3379db7"
      },
      "source": [
        "x_train.shape,x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16000, 2), (4000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-xY0hJ2ie4z"
      },
      "source": [
        "#MODEL 1 - tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT_elwruOgi2"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD4arnOuioqv"
      },
      "source": [
        "if not os.path.isdir('model_save_sgd'):\n",
        "    os.mkdir('model_save_sgd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_hwAxnIH9aS"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(x_train.shape[1],))\n",
        "#Dense hidden layer 1\n",
        "layer1 = Dense(256,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(input_layer)\n",
        "#Dense hidden layer 2\n",
        "layer2 = Dense(128,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer1)\n",
        "#Dense hidden layer 3\n",
        "layer3 = Dense(128,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer2)\n",
        "#Dense hidden layer 4\n",
        "layer4 = Dense(64,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer3)\n",
        "#Dense hidden layer 5\n",
        "layer5 = Dense(32,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer5)\n",
        "#Creating a model\n",
        "model = Model(inputs=input_layer,outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4xCQ2FzWOo1",
        "outputId": "31e31718-ba3d-48b7-bedc-110cc1ccb5cd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               768       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 60,545\n",
            "Trainable params: 60,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOLIjHOki9HA"
      },
      "source": [
        "class TerminateNaN(tf.keras.callbacks.Callback):\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # print(self.model.validation_data[0])\n",
        "        loss = logs.get('loss')\n",
        "        if loss is not None:\n",
        "            if np.isnan(loss) or np.isinf(loss):\n",
        "                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
        "                self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Iy4i94_jaAR"
      },
      "source": [
        "def changeLearningRate(epoch,lr):\n",
        "    # initial_learningrate=0.1\n",
        "    # print(epoch)\n",
        "    if (epoch+1) % 3 == 0:\n",
        "        lr = lr - lr*(0.05)\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQxA4NCAoERS"
      },
      "source": [
        "# class Metrics(Callback):\n",
        "#     # def on_train_begin(self, logs={}):\n",
        "#         # self.val_f1 = []\n",
        "#         # self.val_recalls = []\n",
        "#         # self.val_precisions = []\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         # val_predict = (np.asarray(self.model.predict(x_test))).round()\n",
        "#         # val_targ = y_test#self.model.validation_data[1]\n",
        "#         # _val_f1 = f1_score(val_targ, val_predict)\n",
        "#         # # _val_recall = recall_score(val_targ, val_predict)\n",
        "#         # # _val_precision = precision_score(val_targ, val_predict)\n",
        "#         # self.val_f1.append(_val_f1)\n",
        "#         # self.val_recalls.append(_val_recall)\n",
        "#         # self.val_precisions.append(_val_precision)\n",
        "#         # print “ — val_f1: %f — val_precision: %f — val_recall %f” %(_val_f1, _val_precision, _val_recall)\n",
        "#         logs['f1'] = 2 * (logs['pr'] * logs['re']) / (logs['pr'] + logs['re'])\n",
        "#         print(f'F1 score : ',logs['f1'])\n",
        "#         return\n",
        "# metrics = Metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKFDi5Cl6cnX"
      },
      "source": [
        "##Custom F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guZtREU0G5rz"
      },
      "source": [
        "def f1(y_true,y_pred):\n",
        "    # print(y_pred)\n",
        "    y_pred = K.round(K.clip(y_pred, 0, 1))\n",
        "    return tf.py_function(f1_score,(y_true,y_pred),tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVkWpbPc6dZK"
      },
      "source": [
        "# def f1(y_true, y_pred):\n",
        "    # y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    # y_pred_neg = 1 - y_pred_pos\n",
        "\n",
        "    # y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    # y_neg = 1 - y_pos\n",
        "\n",
        "    # tp = K.sum(y_pos * y_pred_pos)\n",
        "    # tn = K.sum(y_neg * y_pred_neg)\n",
        "\n",
        "    # fp = K.sum(y_neg * y_pred_pos)\n",
        "    # fn = K.sum(y_pos * y_pred_neg)\n",
        "\n",
        "    # pr = tp / (tp + fp)\n",
        "    # re = tp / (tp + fn)\n",
        "\n",
        "    # f1 = (2*pr*re) / (pr + re)\n",
        "    # print(type(y_true.eval(session=None)))\n",
        "\n",
        "\n",
        "    # numerator = (tp * tn - fp * fn)\n",
        "    # denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "\n",
        "    # return 1#f1_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0NdSKkCJ6En"
      },
      "source": [
        "# class LossHistory(tf.keras.callbacks.Callback):\n",
        "    \n",
        "#     def on_train_begin(self, logs={}):\n",
        "#         ## on begin of training, we are creating a instance varible called history\n",
        "#         ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
        "#         self.history={'loss': [],'acc': [],'val_loss': [],'val_acc': [],'f1':[], 'auc' :[], 'precision':[], 'recall':[]}\n",
        "        \n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         ## on end of each epoch, we will get logs and update the self.history dict\n",
        "#         print(logs)\n",
        "#         self.history['loss'].append(logs.get('loss'))\n",
        "#         self.history['acc'].append(logs.get('acc'))\n",
        "#         if logs.get('val_loss', -1) != -1:\n",
        "#             self.history['val_loss'].append(logs.get('val_loss'))\n",
        "#         if logs.get('val_acc', -1) != -1:\n",
        "#             self.history['val_acc'].append(logs.get('val_acc'))\n",
        "#         if logs.get('auc', -1) != -1:\n",
        "#             self.history['auc'].append(logs.get('auc'))\n",
        "        # if (logs.get('precision', -1) != -1) and (logs.get('recall', -1) != -1):\n",
        "        #     f1 = 2*((logs.get('precision') * logs.get('recall'))/ (logs.get('precision') + logs.get('recall')))\n",
        "        #     self.history['f1'].append(f1)\n",
        "            \n",
        "# history_own=LossHistory() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jobfkgVV6hMp"
      },
      "source": [
        "##Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqq1pKlkXIAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfe5712-ac42-4944-f103-484a089ef159"
      },
      "source": [
        "\n",
        "log_dir=\"/content/model_save_sgd/\" \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "filepath=\"model_save_sgd/weights-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',verbose=1)  #,save_best_only=True\n",
        "# validation_accuracy learning rate\n",
        "val_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9,patience=0)\n",
        "# lr change based on no.of epoch\n",
        "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n",
        "#earlystopping\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
        "#terminate on nan\n",
        "term_nan = TerminateNaN()\n",
        "# here we are creating a list with all the callbacks we want\n",
        "callback_list = [val_lr,lrschedule, earlystop, checkpoint,term_nan,tensorboard_callback]    #,metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_9YZrgWlOy8"
      },
      "source": [
        "opt = tf.keras.optimizers.SGD(learning_rate=10,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d3IB3PH3uBD"
      },
      "source": [
        "\n",
        "        # for layer in self.model.layers:\n",
        "        #     if np.nan in layer:\n",
        "        #         self.model.stop_training = True\n",
        "\n",
        "# lambda_call = LambdaCallback(on_epoch_end= lambda epochs, logs: model.stop_training = True if np.nan in np.ravel(np.array([layer.get_weights() for layer in model.layers])))\n",
        "# model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQrfQWNrIW-i"
      },
      "source": [
        "# model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision(name='pr'),tf.keras.metrics.Recall(name='re')])#,tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0uEmVQ1-28S"
      },
      "source": [
        "\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy',tf.keras.metrics.AUC(),f1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY0gxwgPHME_",
        "outputId": "51153181-206d-408b-bfec-2fd7f1eba530"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=10, validation_data=(x_test,y_test),batch_size=16, callbacks=callback_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 10.0.\n",
            "   3/1000 [..............................] - ETA: 44s - loss: 32.5158 - accuracy: 0.4167 - auc_1: 0.4330 - f1: 0.0606        WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0143s). Check your callbacks.\n",
            "1000/1000 [==============================] - 40s 5ms/step - loss: 101.8881 - accuracy: 0.5009 - auc_1: 0.5013 - f1: 0.4673 - val_loss: 68.8892 - val_accuracy: 0.5110 - val_auc_1: 0.5110 - val_f1: 0.4906\n",
            "\n",
            "Epoch 00001: saving model to model_save_sgd/weights-01.hdf5\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 10.0.\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 105.8496 - accuracy: 0.5031 - auc_1: 0.5026 - f1: 0.4736 - val_loss: 323.8675 - val_accuracy: 0.4890 - val_auc_1: 0.4890 - val_f1: 0.4717\n",
            "\n",
            "Epoch 00002: saving model to model_save_sgd/weights-02.hdf5\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 8.55.\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 80.8388 - accuracy: 0.4964 - auc_1: 0.4958 - f1: 0.4632 - val_loss: 13.6245 - val_accuracy: 0.4890 - val_auc_1: 0.4890 - val_f1: 0.4717\n",
            "\n",
            "Epoch 00003: saving model to model_save_sgd/weights-03.hdf5\n",
            "Epoch 00003: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRmzQstyHhfR"
      },
      "source": [
        "# model.layers[1].get_weights()\n",
        "# model.add_metric('f1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKKWgIK26kji"
      },
      "source": [
        "##Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDzcytjLookV",
        "outputId": "3a515a47-9c22-4f5d-8887-845b18b18597"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV4_JWvkou5O"
      },
      "source": [
        "# %tensorboard --logdir /content/model_save_sgd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZdKAQPaelql",
        "outputId": "c12bdb24-3630-4f13-dd3e-32b7b55d36a2"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.4958750009536743, 0.5074999928474426, 0.4988124966621399],\n",
              " 'auc': [0.4961993396282196, 0.5093865394592285, 0.4988124966621399],\n",
              " 'f1': [0.4726143479347229, 0.48473894596099854, 0.4819086194038391],\n",
              " 'loss': [41.09354782104492, 39.81825256347656, 99.82398223876953],\n",
              " 'lr': [10, 1, 0],\n",
              " 'val_accuracy': [0.5115000009536743, 0.5115000009536743, 0.5115000009536743],\n",
              " 'val_auc': [0.5114981532096863, 0.5114981532096863, 0.5114981532096863],\n",
              " 'val_f1': [0.4919758439064026, 0.4919758439064026, 0.4919758439064026],\n",
              " 'val_loss': [64.7737808227539, 97.29852294921875, 97.29852294921875]}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jWi-_I6GrvK"
      },
      "source": [
        "#MODEL - 2 (relu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcuKWhfDOb_r"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NirGpnwXGrMp"
      },
      "source": [
        "if not os.path.isdir('model_save_relu'):\n",
        "    os.mkdir('model_save_relu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLWHScK-fgTo"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(x_train.shape[1],))\n",
        "#Dense hidden layer 1\n",
        "layer1 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(input_layer)\n",
        "#Dense hidden layer 2\n",
        "layer2 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer1)\n",
        "#Dense hidden layer 3\n",
        "layer3 = Dense(256,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer2)\n",
        "#Dense hidden layer 4\n",
        "layer4 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer3)\n",
        "#Dense hidden layer 5\n",
        "layer5 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer5)\n",
        "#Creating a model\n",
        "model1 = Model(inputs=input_layer,outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcWE_A-MI6n-"
      },
      "source": [
        "# model1.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision(name='pr'),tf.keras.metrics.Recall(name='re')])#,tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOmAoi1MO_l4"
      },
      "source": [
        "opt = tf.keras.optimizers.SGD(learning_rate=10,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmQbsIYn6pNJ"
      },
      "source": [
        "##Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMsG-Te6O00g",
        "outputId": "4c6c3a7e-e362-4d46-e064-f3f2d1ec50ff"
      },
      "source": [
        "\n",
        "log_dir=\"/content/model_save_relu/\" \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "filepath=\"model_save_relu/weights-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',verbose=1)  #,save_best_only=True\n",
        "# validation_accuracy learning rate\n",
        "val_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9,patience=0)\n",
        "# lr change based on no.of epoch\n",
        "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n",
        "#earlystopping\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
        "#terminate on nan\n",
        "term_nan = TerminateNaN()\n",
        "# here we are creating a list with all the callbacks we want\n",
        "callback_list = [val_lr,lrschedule, earlystop, checkpoint,term_nan,tensorboard_callback]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy_djvfEOJ3L"
      },
      "source": [
        "model1.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy',tf.keras.metrics.AUC(),f1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6eGs-KEI87A",
        "outputId": "bdf3a472-fb9c-4bbc-d82d-ad982081c572"
      },
      "source": [
        "history1 = model1.fit(x_train,y_train,epochs=10, validation_data=(x_test,y_test),batch_size=16, callbacks=callback_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 10.0.\n",
            "   3/1000 [..............................] - ETA: 1:08 - loss: 14941976.0000 - accuracy: 0.6042 - auc: 0.5581 - f1: 0.2000 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_train_batch_end` time: 0.0209s). Check your callbacks.\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 44827.0781 - accuracy: 0.4912 - auc: 0.4916 - f1: 0.3282 - val_loss: 0.7253 - val_accuracy: 0.5008 - val_auc: 0.5000 - val_f1: 0.0000e+00\n",
            "\n",
            "Epoch 00001: saving model to model_save_relu/weights-01.hdf5\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 10.0.\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.2467 - accuracy: 0.5038 - auc: 0.5019 - f1: 0.3303 - val_loss: 2.1571 - val_accuracy: 0.5008 - val_auc: 0.5000 - val_f1: 0.0000e+00\n",
            "\n",
            "Epoch 00002: saving model to model_save_relu/weights-02.hdf5\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 8.55.\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.4357 - accuracy: 0.5002 - auc: 0.5012 - f1: 0.3333 - val_loss: 1.2444 - val_accuracy: 0.5008 - val_auc: 0.5000 - val_f1: 0.0000e+00\n",
            "\n",
            "Epoch 00003: saving model to model_save_relu/weights-03.hdf5\n",
            "Epoch 00003: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aSJW6Kc6sir"
      },
      "source": [
        "##Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVgOfOCLrmkh"
      },
      "source": [
        "# %tensorboard --logdir /content/model_save_relu"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gixpLG8uJHhL",
        "outputId": "c84bedb0-f655-49d8-f716-6f59cf7bee93"
      },
      "source": [
        "history1.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.49806249141693115, 0.49668750166893005, 0.4961875081062317],\n",
              " 'auc_3': [0.49951624870300293, 0.4971032738685608, 0.49379390478134155],\n",
              " 'f1': [0.3242529034614563, 0.32708629965782166, 0.3294018805027008],\n",
              " 'loss': [1.7061606645584106, 1.6221518516540527, 1.3496028184890747],\n",
              " 'lr': [10, 9, 7],\n",
              " 'val_accuracy': [0.49924999475479126,\n",
              "  0.49924999475479126,\n",
              "  0.49924999475479126],\n",
              " 'val_auc_3': [0.5, 0.5, 0.5],\n",
              " 'val_f1': [0.6553722023963928, 0.6553722023963928, 0.6553722023963928],\n",
              " 'val_loss': [1.1186678409576416, 0.8830900192260742, 0.693648636341095]}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br8_tdINJi9a"
      },
      "source": [
        "#MODEL - 3 (relu + he)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBrEPhCpcQSx"
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qirTDLUsRGbZ"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhLqpGKFJh1d"
      },
      "source": [
        "if not os.path.isdir('model_save_relu_he'):\n",
        "    os.mkdir('model_save_relu_he')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9QHNd3iJt_a"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(x_train.shape[1],))\n",
        "#Dense hidden layer 1\n",
        "layer1 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(input_layer)\n",
        "#Dense hidden layer 2\n",
        "layer2 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer1)\n",
        "#Dense hidden layer 3\n",
        "layer3 = Dense(256,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer2)\n",
        "#Dense hidden layer 4\n",
        "layer4 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer3)\n",
        "#Dense hidden layer 5\n",
        "layer5 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.RandomUniform(0,1,seed=30))(layer5)\n",
        "#Creating a model\n",
        "model2 = Model(inputs=input_layer,outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjHvzE7gcMem"
      },
      "source": [
        "# print_weights = LambdaCallback(on_train_batch_begin=lambda batch, logs: print(model.layers[0].get_weights()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIXPBLvy6wXb"
      },
      "source": [
        "##Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKJDHuQMROqf",
        "outputId": "a5ff977d-6d9e-4748-9069-e3ee08587d6f"
      },
      "source": [
        "log_dir=\"/content/model_save_relu_he/\" \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "filepath=\"model_save_relu_he/weights-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',verbose=1)  #,save_best_only=True\n",
        "# validation_accuracy learning rate\n",
        "val_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9,patience=0)\n",
        "# lr change based on no.of epoch\n",
        "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n",
        "#earlystopping\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
        "#terminate on nan\n",
        "term_nan = TerminateNaN()\n",
        "# here we are creating a list with all the callbacks we want\n",
        "callback_list = [val_lr,lrschedule, earlystop, checkpoint,term_nan,tensorboard_callback]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhdlPkWZKdBc"
      },
      "source": [
        "# model2.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision(name='pr'),tf.keras.metrics.Recall(name='re')])#,tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANrV22-wXTsn"
      },
      "source": [
        "opt = tf.keras.optimizers.SGD(1,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4t_VZT2ROFa"
      },
      "source": [
        "model2.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaRUMaBbKi0C",
        "outputId": "c26ef958-8330-4a57-f075-4a69ecfb382a"
      },
      "source": [
        "history2 = model2.fit(x_train,y_train,epochs=10, validation_data=(x_test,y_test),batch_size=16, callbacks=callback_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 1.0.\n",
            "   3/1000 [..............................] - ETA: 26s - loss: nan - accuracy: 0.4375 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0083s). Check your callbacks.\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: nan - accuracy: 0.4998 - val_loss: nan - val_accuracy: 0.5008\n",
            "\n",
            "Epoch 00001: saving model to model_save_relu_he/weights-01.hdf5\n",
            "Invalid loss and terminated at epoch 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvpcgHHRKzDk",
        "outputId": "32948569-78ca-4942-a8c6-8ef5fab06603"
      },
      "source": [
        "history2.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.49918749928474426],\n",
              " 'loss': [nan],\n",
              " 'lr': [1],\n",
              " 'val_accuracy': [0.5007500052452087],\n",
              " 'val_loss': [nan]}"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E81BGjwn6zQT"
      },
      "source": [
        "Terminate on NaN is triggered"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0dl-cYIg0Zq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPDo1yFWg12f"
      },
      "source": [
        "#Best Model ( RELU + HE init + ADAM opt )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK2GWAx2hA5D"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5JWCHX-hA5D"
      },
      "source": [
        "if not os.path.isdir('model_save_best_model'):\n",
        "    os.mkdir('model_save_best_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwddvNk7hA5D"
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(x_train.shape[1],))\n",
        "#Dense hidden layer 1\n",
        "layer1 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(input_layer)\n",
        "#Dense hidden layer 2\n",
        "layer2 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer1)\n",
        "#Dense hidden layer 3\n",
        "layer3 = Dense(256,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer2)\n",
        "#Dense hidden layer 4\n",
        "layer4 = Dense(128,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer3)\n",
        "#Dense hidden layer 5\n",
        "layer5 = Dense(64,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal())(layer4)\n",
        "#output layer\n",
        "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer5)\n",
        "#Creating a model\n",
        "model_best = Model(inputs=input_layer,outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNOBIIp463_Q"
      },
      "source": [
        "##Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrdywZnDhA5D",
        "outputId": "9acb0503-06f9-44e9-88e5-4685dd744d2c"
      },
      "source": [
        "log_dir=\"/content/model_save_best_model/\" \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "\n",
        "filepath=\"model_save_best_model/weights-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',verbose=1)  #,save_best_only=True\n",
        "# validation_accuracy learning rate\n",
        "val_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9,patience=0)\n",
        "# lr change based on no.of epoch\n",
        "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n",
        "#earlystopping\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
        "#terminate on nan\n",
        "term_nan = TerminateNaN()\n",
        "# here we are creating a list with all the callbacks we want\n",
        "callback_list = [val_lr,lrschedule, earlystop, checkpoint,term_nan,tensorboard_callback]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQoyYBYahA5E"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF5U82IkhA5E"
      },
      "source": [
        "model_best.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy',f1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4hJxQxUhA5E",
        "outputId": "61067576-5b44-45d8-ce10-a82636feec49"
      },
      "source": [
        "history_best = model_best.fit(x_train,y_train,epochs=10, validation_data=(x_test,y_test),batch_size=16, callbacks=callback_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "   3/1000 [..............................] - ETA: 42s - loss: 3.6890 - accuracy: 0.4583 - f1: 0.6210 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_train_batch_end` time: 0.0132s). Check your callbacks.\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7026 - accuracy: 0.5081 - f1: 0.2856 - val_loss: 0.6942 - val_accuracy: 0.4992 - val_f1: 0.6554\n",
            "\n",
            "Epoch 00001: saving model to model_save_best_model/weights-01.hdf5\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6934 - accuracy: 0.4989 - f1: 0.3425 - val_loss: 0.6933 - val_accuracy: 0.4992 - val_f1: 0.6554\n",
            "\n",
            "Epoch 00002: saving model to model_save_best_model/weights-02.hdf5\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.008549999631941318.\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6934 - accuracy: 0.5001 - f1: 0.3312 - val_loss: 0.6932 - val_accuracy: 0.4992 - val_f1: 0.6554\n",
            "\n",
            "Epoch 00003: saving model to model_save_best_model/weights-03.hdf5\n",
            "Epoch 00003: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASO5CwTv66eC"
      },
      "source": [
        "##Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2H8ydlNvBbG"
      },
      "source": [
        "!kill 2790"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKsI1gr0g2-x"
      },
      "source": [
        "# %tensorboard --logdir /content/model_save_relu"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnH1hfc8u_Ob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xciNO4M2683B"
      },
      "source": [
        "#Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5GPdDPD7g2K"
      },
      "source": [
        "* We have implemented 4 models as described in the task\n",
        "* Early stopping is occuring in most cases as the alidation accuracy is not improving in more than 2 epochs (patience =2) . Though in one case, we can see the loss value turns out to be NaN and hence the TerminateOn NAN call back is triggered\n",
        "* We can also observe the changes in acuuracy and other parameters in tensorboard for each epoch \n",
        "* The best model, with ADAM optimizer seems to have reached a similar accuracy of the other models in less number of iterations\n",
        "* With this assignment, we've explored several callback that can be used to monitor the train phase in granular level like on end of epoch/start of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7mHVdI56-az"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}