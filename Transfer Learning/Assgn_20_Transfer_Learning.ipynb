{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Assgn - 20 - Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0zs3TflcAEr"
      },
      "source": [
        "<pre>\n",
        "1. Download all the data in this folder https://drive.google.com/open?id=1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu. it contains two file both images and labels. The label file list the images and their categories in the following format:\n",
        "            <b>path/to/the/image.tif,category</b>\n",
        "            \n",
        "    where the categories are numbered 0 to 15, in the following order:\n",
        "\n",
        "    <b>0 letter\n",
        "    1 form\n",
        "    2 email\n",
        "    3 handwritten\n",
        "    4 advertisement\n",
        "    5 scientific report\n",
        "    6 scientific publication\n",
        "    7 specification\n",
        "    8 file folder\n",
        "    9 news article\n",
        "    10 budget\n",
        "    11 invoice\n",
        "    12 presentation\n",
        "    13 questionnaire\n",
        "    14 resume\n",
        "    15 memo</b>\n",
        "    \n",
        "2. On this image data, you have to train 3 types of models as given below. You have to split the data into Train and Validation data.\n",
        "\n",
        "3. Try not to load all the images into memory, use the gernarators that we have given the reference notebooks to load the batch of images only during the train data.\n",
        "or you can use this method also\n",
        "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1</a>\n",
        "\n",
        "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c</a>\n",
        "\n",
        "\n",
        "4. You are free to choose Learning rate, optimizer, loss function, image augmentation, any hyperparameters. but you have to use the same architechture what we are asking below. \n",
        "\n",
        "5. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "Note: fit_genarator() method will have problems with the tensorboard histograms, try to debug it, if you could not do use histgrams=0 i.e don't include histograms, check the documentation of tensorboard for more information. \n",
        "\n",
        "6. You can check about Transfer Learning in this link - <a href='https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html'>https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZXpEZtJcAEu"
      },
      "source": [
        "### Model-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF12MYu1cAEy"
      },
      "source": [
        "<pre>\n",
        "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights. \n",
        "2. After VGG-16 network without FC layers, add a new Conv block ( 1 Conv layer and 1 Maxpooling ), 2 FC layers and a output layer to classify 16 classes. You are free to choose any hyperparameters/parameters of conv block, FC layers, output layer. \n",
        "3. Final architecture will be <b>INPUT --> VGG-16 without Top layers(FC) --> Conv Layer --> Maxpool Layer --> 2 FC layers --> Output Layer</b>\n",
        "4. Train only new Conv block, FC layers, output layer. Don't train the VGG-16 network. \n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De0UlsaOcAE1"
      },
      "source": [
        "### Model-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNXN3EXFcAE5"
      },
      "source": [
        "<pre>\n",
        "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights.\n",
        "2. After VGG-16 network without FC layers, don't use FC layers, use conv layers only as Fully connected layer. any FC layer can be converted to a CONV layer. This conversion will reduce the No of Trainable parameters in FC layers. For example, an FC layer with K=4096 that is looking at some input volume of size 7×7×512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096. In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1×1×4096 since only a single depth column “fits” across the input volume, giving identical result as the initial FC layer. You can refer <a href='http://cs231n.github.io/convolutional-networks/#convert'>this</a> link to better understanding of using Conv layer in place of fully connected layers.\n",
        "3. Final architecture will be VGG-16 without FC layers(without top), 2 Conv layers identical to FC layers, 1 output layer for 16 class classification. <b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>\n",
        "3. Train only last 2 Conv layers identical to FC layers, 1 output layer. Don't train the VGG-16 network. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amKbfojfcAE-"
      },
      "source": [
        "### Model-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AULF-PcAFC"
      },
      "source": [
        "<pre>\n",
        "1. Use same network as Model-2 '<b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>' and train only Last 6 Layers of VGG-16 network, 2 Conv layers identical to FC layers, 1 output layer.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcf2Sk_Ng5U7"
      },
      "source": [
        "#Getting the data from kaggle & extracting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmw1w2dkg4ta"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUG1PPfMW70b",
        "outputId": "ca51f478-a150-4aae-9627-a83bd0f8e0a8"
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,ta;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-data-sets/836734/1428684/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210930%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210930T170957Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=37317e8c3028bfabf9e3b8124ef1a0bd1366da1c9abf64f1d01ad2a24b2101c6bcbabff529d4c9b15744967889cb835ab47d2cc5f540e62a10b9d8c4614387df867b74b5137617256c7b493cea5f5cde4c570a28424bccd62d5f5fbda20b4ac7c78790ca913038bad133076a621030e9daa5e7be84acdfa5af98db37ee0dd9f8133e20b10c78a6f78f5d99f0ef05e92e79b15b15b3a407d53155a0be41e26039b50d703aba0463c400f653a31d24e2dfa3616728a5f51af7c56c05dd9d7e3254c743f3650d4c437c92a83eb2f063cb7e210cfdc20cbd7b2b87b8582287fd2310d39f7bbedfba345af3f2822140eed912fb5be9649d74dc01026888bba540d0b3\" -c -O 'archive.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-01 04:18:13--  https://storage.googleapis.com/kaggle-data-sets/836734/1428684/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210930%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210930T170957Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=37317e8c3028bfabf9e3b8124ef1a0bd1366da1c9abf64f1d01ad2a24b2101c6bcbabff529d4c9b15744967889cb835ab47d2cc5f540e62a10b9d8c4614387df867b74b5137617256c7b493cea5f5cde4c570a28424bccd62d5f5fbda20b4ac7c78790ca913038bad133076a621030e9daa5e7be84acdfa5af98db37ee0dd9f8133e20b10c78a6f78f5d99f0ef05e92e79b15b15b3a407d53155a0be41e26039b50d703aba0463c400f653a31d24e2dfa3616728a5f51af7c56c05dd9d7e3254c743f3650d4c437c92a83eb2f063cb7e210cfdc20cbd7b2b87b8582287fd2310d39f7bbedfba345af3f2822140eed912fb5be9649d74dc01026888bba540d0b3\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.219.128, 209.85.146.128, 209.85.147.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.219.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4658501240 (4.3G) [application/zip]\n",
            "Saving to: ‘archive.zip’\n",
            "\n",
            "archive.zip         100%[===================>]   4.34G  43.2MB/s    in 81s     \n",
            "\n",
            "2021-10-01 04:19:34 (55.2 MB/s) - ‘archive.zip’ saved [4658501240/4658501240]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsMdgUCSXUK2",
        "outputId": "7f69a5db-e5ca-406e-ad3a-d88d5114b99e"
      },
      "source": [
        "!pip install patool"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 1.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOhWajbneHPQ",
        "outputId": "7c66e760-9ac2-4cc1-ba75-24e18b0dbb31"
      },
      "source": [
        "!pip uninstall keras-preprocessing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Keras-Preprocessing 1.1.2\n",
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/Keras_Preprocessing-1.1.2.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras_preprocessing/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMiCRFXJeMBV",
        "outputId": "81c4a9e7-3189-4ab7-96a2-c41201203907"
      },
      "source": [
        "!pip install git+https://github.com/keras-team/keras-preprocessing.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-preprocessing.git\n",
            "  Cloning https://github.com/keras-team/keras-preprocessing.git to /tmp/pip-req-build-q1qv90v5\n",
            "  Running command git clone -q https://github.com/keras-team/keras-preprocessing.git /tmp/pip-req-build-q1qv90v5\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.19.5)\n",
            "Building wheels for collected packages: Keras-Preprocessing\n",
            "  Building wheel for Keras-Preprocessing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-Preprocessing: filename=Keras_Preprocessing-1.1.2-py3-none-any.whl size=43632 sha256=84f1eac77b0fecba35c64e359e69868a1baa0da9129a1cc0053dec867533c2bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tdroklq6/wheels/6d/8c/1d/f7c16ffd97b199cf4a20b04f1b9444a9390272edafb52c45f7\n",
            "Successfully built Keras-Preprocessing\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkSeLje6YTiN"
      },
      "source": [
        "import patoolib\n",
        "import pandas as pd\n",
        "\n",
        "# Import from keras_preprocessing not from keras.preprocessing\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D , Conv1D , MaxPooling1D\n",
        "# from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt91wB36Mex4"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "64hxCpkhYWaO",
        "outputId": "a643f899-a3a4-4628-b4b3-451d03507e06"
      },
      "source": [
        "patoolib.extract_archive('/content/archive.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/archive.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_0wt0g0d5 -- /content/archive.zip\n",
            "patool: ... /content/archive.zip extracted to `archive' (multiple files in root).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'archive'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CKytm6XYc_L"
      },
      "source": [
        "df = pd.read_csv('/content/archive/labels_final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_2iGZomOaCsM",
        "outputId": "3f9e0512-eadf-444e-b020-e2ba2b4cb464"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         path  label\n",
              "0  imagesv/v/o/h/voh71d00/509132755+-2755.tif      3\n",
              "1        imagesl/l/x/t/lxt19d00/502213303.tif      3\n",
              "2       imagesx/x/e/d/xed05a00/2075325674.tif      2\n",
              "3  imageso/o/j/b/ojb60d00/517511301+-1301.tif      3\n",
              "4       imagesq/q/z/k/qzk17e00/2031320195.tif      7"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqdHkEQUjWRg",
        "outputId": "cd70a0d9-6aae-4b13-b465-3a7d9af3302a"
      },
      "source": [
        "36000/64 , 12000/64"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(562.5, 187.5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbEMIQgymIAK"
      },
      "source": [
        "df['label'] = df['label'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN3eFUH-s20e"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teGyDhDLs2wV"
      },
      "source": [
        "img = cv2.imread('/content/archive/data_final/imagesa/a/a/a/aaa11d00/515558347+-8348.tif', cv2.IMREAD_UNCHANGED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE8aquE5s2td",
        "outputId": "803d4318-becb-46a4-b71d-881e9fa24ba7"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 754)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLQIuBuVs2qO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_S18LLjs2nI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hVgRhHWjE45"
      },
      "source": [
        "#Getting data using ImageGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CeBu7a_l9rF"
      },
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ZonHA9dfJ5"
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwyp5wlbaHun",
        "outputId": "0c26e558-21d0-47f1-c106-c879ef1307c3"
      },
      "source": [
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=df,\n",
        "directory=\"/content/archive/data_final/\",\n",
        "x_col=\"path\",\n",
        "y_col=\"label\",\n",
        "subset=\"training\",\n",
        "batch_size=batch_size,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 36000 validated image filenames belonging to 16 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98P9BrcrlmhF",
        "outputId": "83b4b777-5413-4d3f-ef45-30bb5a281b57"
      },
      "source": [
        "valid_generator=datagen.flow_from_dataframe(\n",
        "dataframe=df,\n",
        "directory=\"/content/archive/data_final/\",\n",
        "x_col=\"path\",\n",
        "y_col=\"label\",\n",
        "subset=\"validation\",\n",
        "batch_size=batch_size,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12000 validated image filenames belonging to 16 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WyPX-kkmZYz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4GKSXKBnVnT"
      },
      "source": [
        "#MODEL -1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNgosbWvbnj5"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DEmMwCCnYAr",
        "outputId": "1a5aea56-f0e7-47fc-f3a4-cb3398b1685a"
      },
      "source": [
        "base_model = VGG16(include_top=False,input_shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj5_Zh4Dr1jO"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ3fhhHwwbAj"
      },
      "source": [
        "top_model = base_model.output\n",
        "\n",
        "#Conv layer\n",
        "top_model = Conv2D(64,3,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal(),name=\"conv_1\",)(top_model)\n",
        "\n",
        "#Maxpool layer\n",
        "top_model = MaxPooling2D(pool_size=(2,2),strides=(2,2),name='max_pooling')(top_model)\n",
        "top_model = Flatten(name='flatten')(top_model)\n",
        "\n",
        "# 2 FC layers\n",
        "top_model = Dense(512,kernel_initializer=tf.keras.initializers.HeNormal(), activation='relu')(top_model)\n",
        "top_model = Dense(128,kernel_initializer=tf.keras.initializers.HeNormal(), activation='relu')(top_model)\n",
        "# top_model = Dropout(0.2)(top_model)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(16, activation='softmax')(top_model)\n",
        "\n",
        "model1 = Model(inputs = base_model.input, outputs = output_layer, \n",
        "               name = \"Model-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HNT5S0UT3av",
        "outputId": "e81efce6-5d7b-45a4-ea81-3fe9ac3c886c"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model-1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_1 (Conv2D)              (None, 5, 5, 64)          294976    \n",
            "_________________________________________________________________\n",
            "max_pooling (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 15,208,976\n",
            "Trainable params: 494,288\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRQMb9awRH2E"
      },
      "source": [
        "opt = Adam(0.001)\n",
        "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPjao66QtyEH"
      },
      "source": [
        "import os\n",
        "if not os.path.isdir('logs'):\n",
        "    os.mkdir('logs')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WKyNTDEG8VO"
      },
      "source": [
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='/content/logs',histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JulXEcKNXKS3"
      },
      "source": [
        "train_step = train_generator.samples// batch_size\n",
        "valid_step = valid_generator.samples // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZh1bjj0kll9",
        "outputId": "51dedead-1b13-4a56-b8b7-0958d8dc9a05"
      },
      "source": [
        "36000/32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1125.0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nwT5EwziDN-",
        "outputId": "4979fa2d-4a22-4897-ddc5-0796c530bc09"
      },
      "source": [
        "train_generator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator at 0x7f2a73c895d0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTssfyIrWJ5a",
        "outputId": "5da962c9-14e6-4777-e091-ae41e5982e61"
      },
      "source": [
        "hist = model1.fit(train_generator,\n",
        "                  batch_size=batch_size,\n",
        "                            steps_per_epoch= train_step,\n",
        "                            epochs=3,\n",
        "                            validation_data=valid_generator,\n",
        "                            validation_steps=valid_step,\n",
        "                                    callbacks = [tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1125/1125 [==============================] - 462s 372ms/step - loss: 1.4171 - accuracy: 0.5629 - val_loss: 1.1498 - val_accuracy: 0.6507\n",
            "Epoch 2/3\n",
            "1125/1125 [==============================] - 364s 324ms/step - loss: 1.0396 - accuracy: 0.6811 - val_loss: 1.0566 - val_accuracy: 0.6830\n",
            "Epoch 3/3\n",
            "1125/1125 [==============================] - 364s 323ms/step - loss: 0.8999 - accuracy: 0.7243 - val_loss: 1.0439 - val_accuracy: 0.6852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CiE0_ySMT2d"
      },
      "source": [
        "# %tensorboard --logdir /content/logs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4FJHwVYqWxY"
      },
      "source": [
        "#MODEL - 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSXMWc9xYk4L"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW2nDUI27cqQ"
      },
      "source": [
        "# base_model = VGG16(include_top=False,input_shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIqOOUlj7hLu"
      },
      "source": [
        "second_model = base_model.output\n",
        "\n",
        "#2CONV layers\n",
        "second_model = Conv1D(filters=64,kernel_size=7,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal(),name=\"conv_1d\")(second_model)\n",
        "second_model = Conv1D(filters=32,kernel_size=1,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal(),name=\"conv_1d_2\")(second_model)\n",
        "second_model = Flatten(name='flatten_1_second')(second_model)\n",
        "\n",
        "# Output layer\n",
        "output_layer_second = Dense(16, activation='softmax',name='output')(second_model)\n",
        "\n",
        "\n",
        "model2 = Model(inputs = base_model.input, outputs = output_layer_second, \n",
        "               name = \"Model-2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQguEtD8-nUh",
        "outputId": "c6805709-a14b-45f6-df4e-504c87292923"
      },
      "source": [
        "base_model.output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 7, 7, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMY1JcaWD2Ad",
        "outputId": "610c96bf-32a1-4dae-bbf3-4579b8338eb1"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model-2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_1d (Conv1D)             (None, 7, 1, 64)          229440    \n",
            "_________________________________________________________________\n",
            "conv_1d_2 (Conv1D)           (None, 7, 1, 32)          2080      \n",
            "_________________________________________________________________\n",
            "flatten_1_second (Flatten)   (None, 224)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 16)                3600      \n",
            "=================================================================\n",
            "Total params: 14,949,808\n",
            "Trainable params: 235,120\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQmv_V1rFC_g"
      },
      "source": [
        "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5X-YYlFNyWH"
      },
      "source": [
        "\n",
        "if not os.path.isdir('logs2'):\n",
        "    os.mkdir('logs2')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mpjgdg7NyWI"
      },
      "source": [
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='/content/logs2',histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZAe0uiBNrXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmhOZh2aGFtH",
        "outputId": "a3f739f7-eb23-499f-82c0-e992eca75a2b"
      },
      "source": [
        "hist_2 = model2.fit(train_generator,\n",
        "                  batch_size=batch_size,\n",
        "                            steps_per_epoch= train_step,\n",
        "                            epochs=5,\n",
        "                            validation_data=valid_generator,\n",
        "                            validation_steps=valid_step,\n",
        "                    callbacks = [tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1125/1125 [==============================] - 369s 327ms/step - loss: 1.6256 - accuracy: 0.4924 - val_loss: 1.3511 - val_accuracy: 0.5858\n",
            "Epoch 2/5\n",
            "1125/1125 [==============================] - 367s 326ms/step - loss: 1.2429 - accuracy: 0.6150 - val_loss: 1.2672 - val_accuracy: 0.6168\n",
            "Epoch 3/5\n",
            "1125/1125 [==============================] - 368s 327ms/step - loss: 1.1252 - accuracy: 0.6489 - val_loss: 1.2099 - val_accuracy: 0.6321\n",
            "Epoch 4/5\n",
            "1125/1125 [==============================] - 370s 329ms/step - loss: 1.0509 - accuracy: 0.6744 - val_loss: 1.1309 - val_accuracy: 0.6584\n",
            "Epoch 5/5\n",
            "1125/1125 [==============================] - 370s 329ms/step - loss: 0.9967 - accuracy: 0.6898 - val_loss: 1.1099 - val_accuracy: 0.6601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4isEt_GPuM"
      },
      "source": [
        "# %tensorboard --logdir /content/logs2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccbzrO_gNbC3"
      },
      "source": [
        "#MODEL - 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ9z8q8FNdGb"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB8lp4q0NfqC"
      },
      "source": [
        "for layer in base_model.layers[-8:]:                                        #excluding 2 maxpool layers\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHLmdXLxNtpt"
      },
      "source": [
        "third_model = base_model.output\n",
        "\n",
        "third_model = Conv1D(filters=64,kernel_size=7,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal(),name=\"conv_1d\")(third_model)\n",
        "third_model = Conv1D(filters=32,kernel_size=1,activation='relu',kernel_initializer=tf.keras.initializers.HeNormal(),name=\"conv_1d_2\")(third_model)\n",
        "third_model = Flatten(name='flatten_1_third')(third_model)\n",
        "output_layer_second = Dense(16, activation='softmax',name='output')(third_model)\n",
        "\n",
        "\n",
        "model3 = Model(inputs = base_model.input, outputs = output_layer_second, \n",
        "               name = \"Model-3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT6gPrs5OOnk",
        "outputId": "9741c31c-d8f5-4693-8112-32f383c7c87f"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model-3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_1d (Conv1D)             (None, 7, 1, 64)          229440    \n",
            "_________________________________________________________________\n",
            "conv_1d_2 (Conv1D)           (None, 7, 1, 32)          2080      \n",
            "_________________________________________________________________\n",
            "flatten_1_third (Flatten)    (None, 224)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 16)                3600      \n",
            "=================================================================\n",
            "Total params: 14,949,808\n",
            "Trainable params: 13,214,320\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mit61BJTOQ6f"
      },
      "source": [
        "model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l4E9RC_VxlV"
      },
      "source": [
        "\n",
        "if not os.path.isdir('logs3'):\n",
        "    os.mkdir('logs3')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVVZ5GKsVxlW"
      },
      "source": [
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='/content/logs3',histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzCM79BXVt5X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjrATdl0Ofca",
        "outputId": "49a2c68a-204d-4808-8259-ddf82d2edd15"
      },
      "source": [
        "hist_3 = model3.fit(train_generator,\n",
        "                  batch_size=batch_size,\n",
        "                            steps_per_epoch= train_step,\n",
        "                            epochs=3,\n",
        "                            validation_data=valid_generator,\n",
        "                            validation_steps=valid_step,\n",
        "                    callbacks = [tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1125/1125 [==============================] - 499s 442ms/step - loss: 3.1228 - accuracy: 0.0624 - val_loss: 2.7728 - val_accuracy: 0.0593\n",
            "Epoch 2/3\n",
            "1125/1125 [==============================] - 496s 441ms/step - loss: 2.7728 - accuracy: 0.0629 - val_loss: 2.7729 - val_accuracy: 0.0613\n",
            "Epoch 3/3\n",
            "1125/1125 [==============================] - 497s 441ms/step - loss: 2.7728 - accuracy: 0.0600 - val_loss: 2.7730 - val_accuracy: 0.0584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjHKur9AOnMI"
      },
      "source": [
        "# %tensorboard --logdir /content/logs3"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESGJwUCtb9Zl"
      },
      "source": [
        "#Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mZQfiAOb_gZ"
      },
      "source": [
        "* As mentioned in the assignment task, the 3rd model in which the last 6 layers of the base model was traind has a comparatively low accuracy of around 6%. The other 2 models has an accuracy of greater than 60%.\n",
        "* Also, datagenerator was used to rescale and feed data into model when training in a dynamic manner\n",
        "* Tensorboard for each model has been plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GatHq5Vb-tg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}